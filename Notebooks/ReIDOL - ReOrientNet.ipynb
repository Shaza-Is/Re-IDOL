{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203a9682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import glob\n",
    "\n",
    "print(\"Using TensorFlow version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8688882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbf8e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3425d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 11:15:09.631523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:09.635655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:09.635840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3882afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Concatenate, Dense, Flatten ,Activation ,Input , BatchNormalization,Dropout , Bidirectional\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc10f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3cdb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "building1_filenames = set(glob.glob(\"../datasets/building1/*/*.feather\"))\n",
    "building2_filenames = set(glob.glob(\"../datasets/building2/*/*.feather\"))\n",
    "building3_filenames = set(glob.glob(\"../datasets/building3/*/*.feather\"))\n",
    "training_filenames = set(glob.glob(\"../datasets/building1/known/7*.feather\"))\n",
    "#test1_filenames = building1_filenames - training_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cd02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=100\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0fd1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training samples\n",
    "\n",
    "dfs = []\n",
    "for file in training_filenames:\n",
    "    df = pd.read_feather(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "training_data = pd.concat(dfs, ignore_index=True)\n",
    "training_data[\"iphoneAccX\"] = -1*training_data[\"iphoneAccX\"]\n",
    "training_data[\"iphoneAccY\"] = -1*training_data[\"iphoneAccY\"]\n",
    "training_data[\"iphoneGyroX\"] = -1*training_data[\"iphoneGyroX\"]\n",
    "training_data[\"iphoneGyroY\"] = -1*training_data[\"iphoneGyroY\"]\n",
    "training_data[\"iphoneMagX\"] = -1*training_data[\"iphoneMagX\"]\n",
    "training_data[\"iphoneMagY\"] = -1*training_data[\"iphoneMagY\"]\n",
    "#training_data.head()\n",
    "\n",
    "orientation_acc = training_data[[\"iphoneAccX\", \"iphoneAccY\", \"iphoneAccZ\"]]\n",
    "orientation_gyro = training_data[[\"iphoneGyroX\", \"iphoneGyroY\", \"iphoneGyroZ\"]]\n",
    "orientation_mag = training_data[[\"iphoneMagX\", \"iphoneMagY\", \"iphoneMagZ\"]] \n",
    "\n",
    "#orientation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d825b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientX</th>\n",
       "      <th>orientY</th>\n",
       "      <th>orientZ</th>\n",
       "      <th>orientW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025497</td>\n",
       "      <td>-0.010281</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.999622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025480</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.999622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025527</td>\n",
       "      <td>-0.010327</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.999621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.999622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025504</td>\n",
       "      <td>-0.010333</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.999621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orientX   orientY   orientZ   orientW\n",
       "0  0.025497 -0.010281  0.000252  0.999622\n",
       "1  0.025480 -0.010309  0.000230  0.999622\n",
       "2  0.025527 -0.010327  0.000246  0.999621\n",
       "3  0.025486 -0.010316  0.000241  0.999622\n",
       "4  0.025504 -0.010333  0.000285  0.999621"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_target = training_data[[\"orientX\", \"orientY\", \"orientZ\", \"orientW\"]] \n",
    "orientation_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c516ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_np = orientation_acc.to_numpy()\n",
    "gyro_np = orientation_gyro.to_numpy()\n",
    "mag_np = orientation_mag.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94417eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65652"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orient_np = orientation_target.to_numpy()\n",
    "len(orient_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d09550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_samples(acc_, gyro_, mag_, orient_, batch_size = 64):\n",
    "    while True:\n",
    "        xa_batch = np.zeros((batch_size,100,3))\n",
    "        xg_batch = np.zeros((batch_size,100,3))\n",
    "        xm_batch = np.zeros((batch_size,100,3))\n",
    "        y_theta_batch = np.zeros((batch_size,4))\n",
    "        #y_sigma_batch = np.finfo(np.float32).eps* np.ones((batch_size,6)) ## To remove\n",
    "        #y_batch = np.concatenate((y_theta_batch, y_sigma_batch), axis=1)\n",
    "        #print(y_batch.shape)\n",
    "        \n",
    "        j = 0\n",
    "        for i in range(len(orient_)):\n",
    "            xa_batch[j,:,:] = acc_[i, :]\n",
    "            xg_batch[j,:,:] = gyro_[i,:]\n",
    "            xm_batch[j,:,:] = mag_[i,:]\n",
    "            y_theta_batch[j,:4] = orient_[i,:]\n",
    "            j += 1\n",
    "            if j >= batch_size:\n",
    "                j = 0              \n",
    "                yield([xa_batch,xg_batch, xm_batch],[y_theta_batch])\n",
    "            #---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = os.path.join(os.getcwd(),'../datasets/CheckPoints_Model_OrientNet_Building1_File_7')\n",
    "\n",
    "if not os.path.exists(checkpoints_path):\n",
    "  os.mkdir(checkpoints_path)\n",
    "check_point_template_path = os.path.join(checkpoints_path,'ckpt_epoch_{epoch:03d}_loss_{loss:.4f}_.hdf5') # vloss_{val_loss:.4f}\n",
    "check_point_callback = tf.keras.callbacks.ModelCheckpoint(check_point_template_path)\n",
    "\n",
    "import re #regular expresion\n",
    "def get_all_checkpoints(checkpoints_path,checkpoint_main_name = 'ckpt'):\n",
    "  all_checkpoints = [j for j in os.listdir(checkpoints_path) if j.startswith(checkpoint_main_name)]\n",
    "  return all_checkpoints\n",
    "\n",
    "def check_if_available_checkpoints(checkpoints_path,checkpoint_main_name = 'ckpt'):\n",
    "  all_checkpoints = get_all_checkpoints(checkpoints_path,checkpoint_main_name)\n",
    "  if(len(all_checkpoints) > 0):#checkpoints avilable\n",
    "    all_checkpoints.sort(reverse=True)    \n",
    "    latest_check_point = all_checkpoints[0]\n",
    "    initial_epoch = int(re.search('epoch_(.*?)_', latest_check_point).group(1))    \n",
    "  else:\n",
    "    latest_check_point = None\n",
    "    initial_epoch = 0\n",
    "    \n",
    "  return initial_epoch , latest_check_point\n",
    "\n",
    "\n",
    "# Check if there are any check points initially\n",
    "initial_epoch , latest_check_point = check_if_available_checkpoints(checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d1f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "orient_learning_rate = 0.0005 # convergence  within  20  epochs \\ref{IDOL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc6085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_graphics.geometry.transformation as tfg\n",
    "#def quaterinion_inv(q):\n",
    "#    return (1/(tnp.sum(q**2))) * tnp.array([-1*q[0], -1*q[1], -1*q[2], q[3]])\n",
    "#\n",
    "#def log_bar(q, batch_size = 64):\n",
    "#    #print(tf.shape(q[3]))\n",
    "#    log_batch = tnp.zeros((batch_size,3))\n",
    "#    log_list = tf.unstack(log_batch)\n",
    "#\n",
    "#    for i in range(batch_size):\n",
    "#        if q[3][i] == 0:\n",
    "#            log_list[i] =tnp.array([0.0, 0.0, 0.0], dtype=tnp.float32)\n",
    "#            #print(tf.shape(log_batch[i]))\n",
    "#        else:\n",
    "#            v = tf.slice(q,\n",
    "#                   begin=[i,0],\n",
    "#                   size=[3,1])\n",
    "#            log_list[i] = tnp.arctan2(tnp.sum(tnp.square(v)), q[3][i])/tnp.sum(tnp.square(v)) * v\n",
    "#    return tf.stack(log_list)\n",
    "#\n",
    "#\n",
    "#def quaternion_multiply(quaternion1, quaternion0):\n",
    "#    #w0, x0, y0, z0 = quaternion0 # ERROR with TF\n",
    "#    #w1, x1, y1, z1 = quaternion1\n",
    "#    w0 = quaternion0[3]\n",
    "#    x0 = quaternion0[0]\n",
    "#    y0 = quaternion0[1]\n",
    "#    z0 = quaternion0[2]\n",
    "#    w1 = quaternion1[3]\n",
    "#    x1 = quaternion1[0]\n",
    "#    y1 = quaternion1[1]\n",
    "#    z1 = quaternion1[2]\n",
    "#    return tnp.array([-x1 * x0 - y1 * y0 - z1 * z0 + w1 * w0,\n",
    "#                     x1 * w0 + y1 * z0 - z1 * y0 + w1 * x0,\n",
    "#                     -x1 * z0 + y1 * w0 + z1 * x0 + w1 * y0,\n",
    "#                     x1 * y0 - y1 * x0 + z1 * w0 + w1 * z0])\n",
    "#\n",
    "#def boximinus(q1, q2):\n",
    "#    return 2 * log_bar(quaternion_multiply(quaterinion_inv(q2), q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea8546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "class OreintLoss(tf.keras.losses.Loss):\n",
    "  def call(self, y_true, y_pred):\n",
    "    # custom loss L_orient = 0.5*(q [-] \\hat{q})^T *Sig^{-1}* \n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    #q = y_true[:, 0:4]                   ##y_true[0:4][:]\n",
    "    q = tf.slice(y_true,\n",
    "                    begin=[0,0],\n",
    "                    size=[-1,4])  \n",
    "\n",
    "\n",
    "    #q_est = y_pred[:, 0:4]   #########y_pred[0:4][:]\n",
    "    q_est = tf.slice(y_pred,\n",
    "                    begin=[0,0],\n",
    "                    size=[-1,4])  \n",
    "\n",
    "\n",
    "    s_00 = tf.math.exp(tf.reshape(tf.slice(y_pred,  #\n",
    "           begin=[0,4],\n",
    "           size=[-1,1]), [-1]))\n",
    "    s_11 = tf.math.exp(tf.reshape(tf.slice(y_pred,  #\n",
    "           begin=[0,5],  \n",
    "           size=[-1,1]), [-1]))\n",
    "    s_22 = tf.math.exp(tf.reshape(tf.slice(y_pred, #\n",
    "           begin=[0,6],\n",
    "           size=[-1,1]), [-1]))\n",
    "    s_01 = tf.math.abs(tf.math.multiply(tf.reshape(tf.slice(y_pred,\n",
    "           begin=[0,7],  \n",
    "           size=[-1,1]), [-1]), tf.math.sqrt(tf.math.multiply(s_00, s_11))))\n",
    "    s_02 = tf.math.abs(tf.math.multiply(tf.reshape(tf.slice(y_pred, \n",
    "           begin=[0,8],    \n",
    "           size=[-1,1]), [-1]), tf.math.sqrt(tf.math.multiply(s_00, s_22))))\n",
    "    s_12 = tf.math.abs(tf.math.multiply(tf.reshape(tf.slice(y_pred,\n",
    "           begin=[0,9],  \n",
    "           size=[-1,1]), [-1]), tf.math.sqrt(tf.math.multiply(s_11, s_22))))\n",
    "\n",
    "           \n",
    "    sig0 = tf.stack([s_00, s_01, s_02], axis=1)\n",
    "    sig1 = tf.stack([s_01, s_11, s_12], axis=1)\n",
    "    sig2 = tf.stack([s_02, s_12, s_22], axis=1)\n",
    "    sig = tf.stack([sig0, sig1, sig2], axis=2)\n",
    "\n",
    "    i = tfg.quaternion.inverse(q_est)\n",
    "\n",
    "    mult_ = tfg.quaternion.multiply(i, q)\n",
    "    log_ = tf.slice(mult_,\n",
    "                    begin=[0,0],\n",
    "                    size=[-1,3])\n",
    "    omega=tf.slice(mult_,\n",
    "              begin=[0,3],\n",
    "              size=[-1,1])\n",
    "\n",
    " \n",
    "    log_ = tf.linalg.normalize(log_, ord='euclidean', axis=None, name=None)\n",
    "    atan_ = tf.atan(tf.divide(log_[1], omega))\n",
    "    v = log_[0]\n",
    "    z = tf.zeros_like(v)\n",
    "    v = tf.where(tf.equal(v, z), tf.zeros_like(v), v)\n",
    "\n",
    "\n",
    "    \n",
    "    delta = tf.math.scalar_mul(2.0, tf.multiply(v, atan_))                  #boximinus(q, q_est)\n",
    "    delta = tf.expand_dims(delta, -1)\n",
    "\n",
    "\n",
    "    #sig = tf.eye(3, batch_shape=[64])#tnp.ones((64,3,3), dtype=tnp.float32)\n",
    "    #sig[:,0, 0] = y_pred[:,4]\n",
    "    #sig[:,1, 1] = y_pred[:,5]\n",
    "    #sig[:,2, 2] = y_pred[:,6]\n",
    "    #sig[:,0, 1] = y_pred[:,7]\n",
    "    #sig[:,1, 0] = y_pred[:,7]\n",
    "    #sig[:,0, 2] = y_pred[:,8]\n",
    "    #sig[:,2, 0] = y_pred[:,8]\n",
    "    #sig[:,1, 2] = y_pred[:,9]\n",
    "    #sig[:,2, 1] = y_pred[:,9]\n",
    "    \n",
    "\n",
    "    \n",
    "    e = tf.math.scalar_mul(tf.keras.backend.epsilon() ,tf.eye(3, batch_shape=[64]))\n",
    "\n",
    "    sig_inv = tf.linalg.inv(tf.add(sig,e)) #  tf.add(sig,e)\n",
    "    m_ = tf.matmul(sig_inv, delta)\n",
    "    m = tf.matmul(delta, m_, transpose_a=True)\n",
    "\n",
    "\n",
    "    l_s = tf.linalg.logdet(sig)\n",
    "\n",
    "    l = tf.math.scalar_mul(0.5, m)  + tf.math.scalar_mul(0.00000000005, l_s) # 0.00000000005 weird factor that worked\n",
    "\n",
    "\n",
    "    return tf.reduce_mean(l)\n",
    "\n",
    "\n",
    "class MyLossP(tf.keras.losses.Loss):\n",
    "  def call(self, y_true, y_pred):\n",
    "    # y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "    # y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    return tf.sqrt(tf.reduce_mean((y_pred - y_true)**2, axis=-1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e51d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac8a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OreintNet():\n",
    "    def build_model(self):\n",
    "        # Building Network\n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        #1. Define inputs\n",
    "        Acc_input = Input(shape=(100,3), batch_size=64 , name = 'Acc_input')    \n",
    "        Gyro_input = Input(shape=(100,3),batch_size=64   , name = 'Gyro_input')\n",
    "        Mag_input = Input(shape=(100,3), batch_size=64   , name = 'Mag_input')\n",
    "        \n",
    "        MergedLayer = Concatenate()([Acc_input , Gyro_input, Mag_input])\n",
    "        #\n",
    "        ##MergedLayer = Input(shape=(9) , name = 'imu_input')\n",
    "        #2. LSTM\n",
    "        LSTM1 = (LSTM(100, kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', return_sequences=True))(MergedLayer) # , return_sequences=True\n",
    "        LSTM2 = (LSTM(100, kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', return_sequences=False))(LSTM1)\n",
    "        #print(\"Output shape of the LSTM layer's output : \", LSTM2.shape)\n",
    "        \n",
    "        #3. Fully-Connected (Theta)\n",
    "        Dense1 = Dense(units=100, input_shape=(64,100), activation='tanh')(LSTM2)\n",
    "        Dense2 = Dense(units=32, activation='tanh')(Dense1)\n",
    "        theta_output = Dense(units=4, name='theta_out')(Dense2) # Sigma Outputs\n",
    "        \n",
    "        #4. Fully-Connected (Sigma)\n",
    "        Dense3 = Dense(units=100, input_shape=(64,100), activation='tanh')(LSTM2) # input_shape=(\n",
    "        Dense4 = Dense(units=32, activation='tanh')(Dense3)\n",
    "        sigma_output = Dense(units=6, activation='sigmoid', name='sig_out')(Dense4) # Theta Outputs  activation='linear'\n",
    "\n",
    "\n",
    "        output = Concatenate()([theta_output, sigma_output])\n",
    "        #5. Define and compile The model\n",
    "        Network = Model([Acc_input,Gyro_input, Mag_input],  [output])  #  [Acc_input,Gyro_input, Mag_input]\n",
    "        Network.compile(loss=OreintLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=orient_learning_rate)) #loss=OreintLoss()\n",
    "        return Network\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb73550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class OreintNet(Model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76017c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from scratch : epochs =  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 11:15:11.212534: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-05 11:15:11.213297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.213734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.213970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.615140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.615358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.615486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 11:15:11.615603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4242 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "network_builder = OreintNet()\n",
    "Nepochs = 20\n",
    "if initial_epoch > 0:\n",
    "  print('continue after epoch' , initial_epoch , ' - checkpoint: ',latest_check_point,' epochs = ',Nepochs)\n",
    "  orientation_network = tf.keras.models.load_model(os.path.join(checkpoints_path,latest_check_point),compile=False)\n",
    "  orientation_network.compile(loss=OreintLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=orient_learning_rate))\n",
    "else:\n",
    "  print('start from scratch : epochs = ', Nepochs)\n",
    "  orientation_network = network_builder.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94fb091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Acc_input (InputLayer)         [(64, 100, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " Gyro_input (InputLayer)        [(64, 100, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " Mag_input (InputLayer)         [(64, 100, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (64, 100, 9)         0           ['Acc_input[0][0]',              \n",
      "                                                                  'Gyro_input[0][0]',             \n",
      "                                                                  'Mag_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (64, 100, 100)       44000       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (64, 100)            80400       ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (64, 100)            10100       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (64, 100)            10100       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (64, 32)             3232        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (64, 32)             3232        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " theta_out (Dense)              (64, 4)              132         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " sig_out (Dense)                (64, 6)              198         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (64, 10)             0           ['theta_out[0][0]',              \n",
      "                                                                  'sig_out[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 151,394\n",
      "Trainable params: 151,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "orientation_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b96adcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 11:15:15.531181: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2021-12-05 11:15:16.002293: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x7d0b940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8/65652 [..............................] - ETA: 18:22 - loss: nan   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 11:15:16.505834: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 0. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505872: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 1. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505881: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 2. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505887: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 3. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505892: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 4. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505898: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 5. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505903: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 6. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505908: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 7. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505914: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 8. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505919: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 9. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505925: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 10. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505931: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 11. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505936: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 12. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505942: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 13. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505947: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 14. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505952: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 15. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505958: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 16. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505963: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 17. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505969: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 18. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505974: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 19. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505981: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 20. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505986: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 21. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505992: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 22. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.505997: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 23. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506002: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 24. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506008: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 25. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506013: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 26. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506018: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 27. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506024: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 28. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506029: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 29. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506034: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 30. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506040: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 31. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506045: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 32. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506050: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 33. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506056: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 34. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506061: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 35. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506066: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 36. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506072: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 37. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506078: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 38. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506083: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 39. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506089: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 40. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506094: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 41. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506099: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 42. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506105: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 43. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506110: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 44. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506115: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 45. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506121: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 46. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506126: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 47. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506131: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 48. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506137: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 49. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506142: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 50. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506148: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 51. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506153: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 52. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506158: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 53. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506164: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 54. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506169: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 55. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506196: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 56. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506201: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 57. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506207: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 58. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506212: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 59. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506218: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 60. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506223: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 61. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506229: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 62. The input might not be valid. Filling lower-triangular output with NaNs.\n",
      "2021-12-05 11:15:16.506235: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:202] Cholesky decomposition was not successful for batch 63. The input might not be valid. Filling lower-triangular output with NaNs.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input is not invertible.\n\t [[node OreintLoss/MatrixInverse\n (defined at /tmp/ipykernel_27865/1661278321.py:82)\n]] [Op:__inference_train_function_6355]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node OreintLoss/MatrixInverse:\nIn[0] OreintLoss/Add:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_27865/1759242162.py\", line 1, in <module>\n>>>     history = orientation_network.fit(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/tmp/ipykernel_27865/1661278321.py\", line 82, in call\n>>>     sig_inv = tf.linalg.inv(tf.add(sig,e)) #  tf.add(sig,e)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27865/1759242162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = orientation_network.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgenerate_training_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgyro_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input is not invertible.\n\t [[node OreintLoss/MatrixInverse\n (defined at /tmp/ipykernel_27865/1661278321.py:82)\n]] [Op:__inference_train_function_6355]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node OreintLoss/MatrixInverse:\nIn[0] OreintLoss/Add:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_27865/1759242162.py\", line 1, in <module>\n>>>     history = orientation_network.fit(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/home/nav-shaza/Desktop/Re-IDOL/.venv/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/tmp/ipykernel_27865/1661278321.py\", line 82, in call\n>>>     sig_inv = tf.linalg.inv(tf.add(sig,e)) #  tf.add(sig,e)\n>>> "
     ]
    }
   ],
   "source": [
    "\n",
    "history = orientation_network.fit(\n",
    "    generate_training_samples(acc_np, gyro_np, mag_np, orient_np),\n",
    "    epochs=Nepochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    steps_per_epoch=len(orient_np),\n",
    "    batch_size=64,\n",
    "    callbacks = [check_point_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e0b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb630921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_learning_rate = 0.001"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99d844438d0062753c8520ac1ef2f592a408c8301da9bb020e092c67b124feb6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
