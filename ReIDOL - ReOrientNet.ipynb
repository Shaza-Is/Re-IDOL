{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "203a9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3882afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Concatenate, Dense, Flatten ,Activation ,Input , BatchNormalization,Dropout , Bidirectional\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc10f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3cdb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "building1_filenames = set(glob.glob(\"datasets/building1/*/*.feather\"))\n",
    "building2_filenames = set(glob.glob(\"datasets/building2/*/*.feather\"))\n",
    "building3_filenames = set(glob.glob(\"datasets/building3/*/*.feather\"))\n",
    "training_filenames = set(glob.glob(\"datasets/building1/train/*.feather\"))\n",
    "test1_filenames = building1_filenames - training_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10cd02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0fd1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training samples\n",
    "\n",
    "dfs = []\n",
    "for file in training_filenames:\n",
    "    df = pd.read_feather(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "training_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#training_data.head()\n",
    "\n",
    "orientation_acc = training_data[[\"iphoneAccX\", \"iphoneAccY\", \"iphoneAccZ\"]]\n",
    "orientation_gyro = training_data[[ \"iphoneGyroX\", \"iphoneGyroY\", \"iphoneGyroZ\"]]\n",
    "orientation_mag = training_data[[ \"iphoneMagX\", \"iphoneMagY\", \"iphoneMagZ\"]] \n",
    "\n",
    "#orientation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientX</th>\n",
       "      <th>orientY</th>\n",
       "      <th>orientZ</th>\n",
       "      <th>orientW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003876</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003858</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003905</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003878</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003889</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orientX   orientY   orientZ   orientW\n",
       "0  0.003876 -0.000046 -0.000105  0.999992\n",
       "1  0.003858 -0.000045 -0.000083  0.999993\n",
       "2  0.003905 -0.000055 -0.000053  0.999992\n",
       "3  0.003878 -0.000063 -0.000048  0.999992\n",
       "4  0.003889 -0.000071 -0.000020  0.999992"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_target = training_data[[\"orientX\", \"orientY\", \"orientZ\", \"orientW\"]] \n",
    "orientation_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35f258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = os.path.join(os.getcwd(),'datasets/CheckPoints_Model_OrientNet')\n",
    "\n",
    "if not os.path.exists(checkpoints_path):\n",
    "  os.mkdir(checkpoints_path)\n",
    "check_point_template_path = os.path.join(checkpoints_path,'ckpt_epoch_{epoch:03d}_loss_{loss:.4f}_vloss_{val_loss:.4f}.hdf5')\n",
    "check_point_callback = tf.keras.callbacks.ModelCheckpoint(check_point_template_path)\n",
    "\n",
    "import re #regular expresion\n",
    "def get_all_checkpoints(checkpoints_path,checkpoint_main_name = 'ckpt'):\n",
    "  all_checkpoints = [j for j in os.listdir(checkpoints_path) if j.startswith(checkpoint_main_name)]\n",
    "  return all_checkpoints\n",
    "\n",
    "def check_if_available_checkpoints(checkpoints_path,checkpoint_main_name = 'ckpt'):\n",
    "  all_checkpoints = get_all_checkpoints(checkpoints_path,checkpoint_main_name)\n",
    "  if(len(all_checkpoints) > 0):#checkpoints avilable\n",
    "    all_checkpoints.sort(reverse=True)    \n",
    "    latest_check_point = all_checkpoints[0]\n",
    "    initial_epoch = int(re.search('epoch_(.*?)_', latest_check_point).group(1))    \n",
    "  else:\n",
    "    latest_check_point = None\n",
    "    initial_epoch = 0\n",
    "    \n",
    "  return initial_epoch , latest_check_point\n",
    "\n",
    "\n",
    "# Check if there are any check points initially\n",
    "initial_epoch , latest_check_point = check_if_available_checkpoints(checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4d1f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "orient_learning_rate = 0.0005 # convergence  within  20  epochs \\ref{IDOL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea8546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "class OreintLoss(tf.keras.losses.Loss):\n",
    "  def call(self, y_true, y_pred):\n",
    "    # custom loss L_orient = 0.5*(q [-] \\hat{q})^T *Sig^{-1}* \n",
    "    W = 25\n",
    "    ws = tf.constant([W,W,1,1,1,1],dtype=tf.float32)\n",
    "    return tf.sqrt(tf.reduce_mean(ws*(y_pred - y_true)**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac8a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OreintNet():\n",
    "    def build_model(self):\n",
    "        # Building Network\n",
    "        #1. Define inputs\n",
    "        Acc_input = Input(shape=(100,3) , name = 'Acc_input')    \n",
    "        Gyro_input = Input(shape=(100,3) , name = 'Gyro_input')\n",
    "        Mag_input = Input(shape=(100,3) , name = 'Mag_input')\n",
    "        \n",
    "        MergedLayer = Concatenate()([Acc_input , Gyro_input, Mag_input])\n",
    "        #\n",
    "        ##MergedLayer = Input(shape=(9) , name = 'imu_input')\n",
    "        #2. LSTM\n",
    "        LSTM1 = (LSTM(100, return_sequences=True))(MergedLayer) # , return_sequences=True\n",
    "        LSTM2 = (LSTM(100, return_sequences=True))(LSTM1)\n",
    "        \n",
    "        #3. Fully-Connected (Sigma)\n",
    "        Dense1 = Dense(units=100, activation='tanh')(LSTM2)\n",
    "        Dense2 = Dense(units=16, activation='tanh')(Dense1)\n",
    "        sigma_output = Dense(units=6, activation='linear')(Dense2) # Sigma Outputs\n",
    "        \n",
    "        #4. Fully-Connected (Theta)\n",
    "        Dense3 = Dense(units=100, activation='tanh')(LSTM2)\n",
    "        Dense4 = Dense(units=16, activation='tanh')(Dense3)\n",
    "        theta_output = Dense(units=6, activation='linear')(Dense4) # Theta Outputs\n",
    "        \n",
    "        #5. Define and compile The model\n",
    "        Network = Model([Acc_input,Gyro_input, Mag_input],  [theta_output]) # , sigma_output])  #  [Acc_input,Gyro_input, Mag_input]\n",
    "        Network.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=orient_learning_rate) ,metrics=['mape']) #loss=OreintLoss()\n",
    "        return Network\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76017c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_builder = OreintNet()\n",
    "orientation_network = network_builder.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f94fb091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Acc_input (InputLayer)          [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Gyro_input (InputLayer)         [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Mag_input (InputLayer)          [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 9)       0           Acc_input[0][0]                  \n",
      "                                                                 Gyro_input[0][0]                 \n",
      "                                                                 Mag_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100, 100)     44000       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 100, 100)     80400       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 100, 100)     10100       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 100, 16)      1616        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 100, 6)       102         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 136,218\n",
      "Trainable params: 136,218\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "orientation_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b96adcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 2087464, 2087464, 2087464\n  y sizes: 2087464, 6\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5186/1177400009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = orientation_network.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     [orientation_acc, \n\u001b[1;32m      4\u001b[0m     \u001b[0morientation_gyro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     orientation_mag],\n",
      "\u001b[0;32m~/Desktop/reIDOL/.venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reIDOL/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reIDOL/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reIDOL/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reIDOL/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1647\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1648\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2087464, 2087464, 2087464\n  y sizes: 2087464, 6\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "Nepochs = 20\n",
    "history = orientation_network.fit(\n",
    "    [orientation_acc, \n",
    "    orientation_gyro,\n",
    "    orientation_mag],\n",
    "    [orientation_target,\n",
    "    np.array([1, 1, 1, 0, 0, 0])],\n",
    "    epochs=Nepochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    batch_size=64,\n",
    "    callbacks = [check_point_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e0b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb630921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_learning_rate = 0.001"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99d844438d0062753c8520ac1ef2f592a408c8301da9bb020e092c67b124feb6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
